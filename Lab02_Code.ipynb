{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvs contain:\n",
    "userId, movieId, rating and tags\n",
    "\n",
    "how many user?\n",
    "\n",
    "# every time run the code it generate the same random number\n",
    "# mix the random number\n",
    "# take the first num of nUsersInExample elements\n",
    "\n",
    "_ is a variable\n",
    "\n",
    "generate the empty list for films & ratings of each user\n",
    "\n",
    "# Movies\n",
    "list_movies:\n",
    "    find the movieID from the userID that we selected\n",
    "    Then give it to \"list_movies_each_user[0]\"\n",
    "\n",
    "# Ratings\n",
    "list_ratings:\n",
    "    find the movieID from the userID that we selected\n",
    "    Then give it to \"list_ratings_each_user[0]\"\n",
    "\n",
    "# User\n",
    "shape[0] is the total num of row\n",
    "shape[1] is the total num of column\n",
    "list_users:\n",
    "    n_each_user * the elements of first 10\n",
    "\n",
    "np.ones((1, n_each_user)) generate the 1D and total num of n_each_user of array\n",
    "\n",
    "for loop to fill in the remaining 1-9 into\n",
    "    list_movies\n",
    "    list_ratings\n",
    "    list_users\n",
    "\n",
    "pd.DataFrame：\n",
    "    generate a D array\n",
    "\n",
    "Y_with_NaNs\n",
    "    row num of unique movies (600)\n",
    "    column num of users (10)\n",
    "\n",
    "np.in1d(indexes_unique_movies, local_movies)\n",
    "    match the value in indexes_unique_movies from the value in local_movies\n",
    "\n",
    "from multi D to 1D\n",
    "    ravel()：如果没有必要，不会产生源数据的副本\n",
    "    flatten()：返回源数据的副本\n",
    "    squeeze()：只能对维数为1的维度降维\n",
    "\n",
    "\n",
    "线性回归的最佳方式是将数据拆分成很多小批次。每个批次都大概具有相同数量的数据点。然后使用每个批次更新权重。这种方法叫做小批次梯度下降法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -> ./ml-latest-small.zip\n",
      "[==============================]   0.933/0.933MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "import pods\n",
    "import zipfile\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pods.util.download_url(\"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\")\n",
    "zip_console = zipfile.ZipFile('ml-latest-small.zip', 'r')\n",
    "for name in zip_console.namelist():\n",
    "           zip_console.extract(name, './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how many user?\n",
    "# cvs contain:\n",
    "# userId, movieId, rating and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "YourStudentID = 20  # Include here the last three digits of your UCard number\n",
    "nUsersInExample = 10 # The maximum number of Users we're going to analyse at one time\n",
    "\n",
    "ratings = pd.read_csv(\"./ml-latest-small/ratings.csv\") \n",
    "# ratings.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# every time run the code it generate the same random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings is a DataFrame with four columns: userId, movieId, rating and tags. \n",
    "\n",
    "# We first want to identify how many unique users there are. \n",
    "\n",
    "# We can use the unique method in pandas\n",
    "\n",
    "indexes_unique_users = ratings['userId'].unique()\n",
    "n_users = indexes_unique_users.shape[0] # 610"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mix the random number\n",
    "## take the first num of nUsersInExample elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119 584 416 304 397  14  94 529 543  13]\n"
     ]
    }
   ],
   "source": [
    "# We randomly select 'nUsers' users with their ratings. We first fix the seed\n",
    "# of the random generator to make sure that we always get the same 'nUsers'\n",
    "\n",
    "np.random.seed(YourStudentID)\n",
    "indexes_users = np.random.permutation(n_users)\n",
    "my_batch_users = indexes_users[0:nUsersInExample]\n",
    "# print(indexes_users)\n",
    "# print(\"-------------------------\")\n",
    "print(my_batch_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _ is a variable generate the empty list for films & ratings of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use now the list of 'my_batch_users' to create a matrix Y. \n",
    "\n",
    "# We need to make a list of the movies that these users have watched\n",
    "list_movies_each_user = [[] for _ in range(nUsersInExample)]\n",
    "list_ratings_each_user = [[] for _ in range(nUsersInExample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies\n",
    "    list_movies:\n",
    "        find the movieID from the userID that we selected\n",
    "        Then give it to \"list_movies_each_user[0]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies\n",
    "list_movies = ratings['movieId'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_movies_each_user[0] = list_movies    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings\n",
    "    list_ratings:\n",
    "        find the movieID from the userID that we selected\n",
    "        Then give it to \"list_ratings_each_user[0]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119, 584, 416, 304, 397,  14,  94, 529, 543,  13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings                      \n",
    "list_ratings = ratings['rating'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_ratings_each_user[0] = list_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User\n",
    "    shape[0] is the total num of row\n",
    "    shape[1] is the total num of column\n",
    "    \n",
    "    my_batch_users 10 people we selected\n",
    "    \n",
    "    list_users:\n",
    "        n_each_user * the elements of first 10\n",
    "    np.ones((1, n_each_user)) generate the 1D and total num of n_each_user of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119. 119. 119. ... 119. 119. 119.]]\n"
     ]
    }
   ],
   "source": [
    "# Users\n",
    "n_each_user = list_movies.shape[0]\n",
    "list_users = my_batch_users[0]*np.ones((1, n_each_user))\n",
    "print(list_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for loop to fill in the remaining 1-9 into\n",
    "        list_movies\n",
    "        list_ratings\n",
    "        list_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.\n",
      "  584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.\n",
      "  584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.\n",
      "  584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.\n",
      "  584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.\n",
      "  584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584. 584.]]\n",
      "[[416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416.\n",
      "  416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416.\n",
      "  416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416. 416.\n",
      "  416. 416. 416. 416. 416. 416. 416. 416. 416.]]\n",
      "[[304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304. 304.\n",
      "  304. 304. 304. 304. 304. 304.]]\n",
      "[[397. 397. 397. 397. 397. 397. 397. 397. 397. 397. 397. 397. 397. 397.\n",
      "  397. 397. 397. 397. 397. 397. 397. 397. 397.]]\n",
      "[[14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14.\n",
      "  14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14.\n",
      "  14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14.]]\n",
      "[[94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94.\n",
      "  94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94.\n",
      "  94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94. 94.\n",
      "  94. 94.]]\n",
      "[[529. 529. 529. 529. 529. 529. 529. 529. 529. 529. 529. 529. 529. 529.\n",
      "  529. 529. 529. 529. 529. 529. 529. 529. 529. 529. 529.]]\n",
      "[[543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543.\n",
      "  543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543.\n",
      "  543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543.\n",
      "  543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543.\n",
      "  543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543. 543.\n",
      "  543. 543. 543. 543. 543. 543.]]\n",
      "[[13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.\n",
      "  13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, nUsersInExample):\n",
    "    # Movies\n",
    "    local_list_per_user_movies = ratings['movieId'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_movies_each_user[i] = local_list_per_user_movies\n",
    "    list_movies = np.append(list_movies,local_list_per_user_movies)\n",
    "    # Ratings                                 \n",
    "    local_list_per_user_ratings = ratings['rating'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_ratings_each_user[i] = local_list_per_user_ratings\n",
    "    list_ratings = np.append(list_ratings, local_list_per_user_ratings)  \n",
    "    # Users                                   \n",
    "    n_each_user = local_list_per_user_movies.shape[0]                                                                               \n",
    "    local_rep_user =  my_batch_users[i]*np.ones((1, n_each_user))\n",
    "    print(local_rep_user)\n",
    "    list_users = np.append(list_users, local_rep_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pd.DataFrame：\n",
    "        generate a D array\n",
    "\n",
    "    Y_with_NaNs\n",
    "        row num of unique movies (600)\n",
    "        column num of users (10)\n",
    "    np.in1d(indexes_unique_movies, local_movies)\n",
    "    match the value in indexes_unique_movies from the value in local_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first see how many unique movies have been rated\n",
    "indexes_unique_movies = np.unique(list_movies)\n",
    "n_movies = indexes_unique_movies.shape[0]\n",
    "# As it is expected no all users have rated all movies. We will build a matrix Y \n",
    "# with NaN inputs and fill according to the data for each user \n",
    "temp = np.empty((n_movies,nUsersInExample,))\n",
    "temp[:] = np.nan\n",
    "Y_with_NaNs = pd.DataFrame(temp)\n",
    "for i in range(nUsersInExample):\n",
    "    local_movies = list_movies_each_user[i]\n",
    "    ixs = np.in1d(indexes_unique_movies, local_movies)\n",
    "    Y_with_NaNs.loc[ixs, i] = list_ratings_each_user[i]\n",
    "\n",
    "Y_with_NaNs.index = indexes_unique_movies.tolist()\n",
    "Y_with_NaNs.columns = my_batch_users.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from multi D to 1D\n",
    "        ravel()：如果没有必要，不会产生源数据的副本\n",
    "        flatten()：返回源数据的副本\n",
    "        squeeze()：只能对维数为1的维度降维\n",
    "\n",
    "\n",
    "    线性回归的最佳方式是将数据拆分成很多小批次。每个批次都大概具有相同数量的数据点。然后使用每个批次更新权重。这种方法叫做小批次梯度下降法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_ratings = np.concatenate(list_ratings_each_user).ravel()\n",
    "p_list_ratings_original = p_list_ratings.tolist()\n",
    "mean_ratings_train = np.mean(p_list_ratings)\n",
    "p_list_ratings =  p_list_ratings - mean_ratings_train # remove the mean\n",
    "p_list_movies = np.concatenate(list_movies_each_user).ravel().tolist()\n",
    "p_list_users = list_users.tolist()\n",
    "Y = pd.DataFrame({'users': p_list_users, 'movies': p_list_movies, 'ratingsorig': p_list_ratings_original,'ratings':p_list_ratings.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>movies</th>\n",
       "      <th>ratingsorig</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.367718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>119.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.132282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.867718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>170</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.132282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>173</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.867718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.867718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3977</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.867718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>821</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3996</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.132282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4011</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.132282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4148</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.132282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     users  movies  ratingsorig   ratings\n",
       "0    119.0       1          3.5 -0.367718\n",
       "1    119.0      10          4.0  0.132282\n",
       "2    119.0      44          3.0 -0.867718\n",
       "3    119.0     170          5.0  1.132282\n",
       "4    119.0     173          3.0 -0.867718\n",
       "..     ...     ...          ...       ...\n",
       "819   13.0    3952          3.0 -0.867718\n",
       "820   13.0    3977          3.0 -0.867718\n",
       "821   13.0    3996          5.0  1.132282\n",
       "822   13.0    4011          5.0  1.132282\n",
       "823   13.0    4148          4.0  0.132282\n",
       "\n",
       "[824 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2 # the dimension of our map of the 'library'\n",
    "learn_rate = 0.01\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gradient(Y, U, V):\n",
    "    gU = pd.DataFrame(np.zeros((U.shape)), index=U.index)\n",
    "    gV = pd.DataFrame(np.zeros((V.shape)), index=V.index)\n",
    "    obj = 0.\n",
    "    nrows = Y.shape[0]\n",
    "    for i in range(nrows):\n",
    "        row = Y.iloc[i]\n",
    "        user = row['users']\n",
    "        film = row['movies']\n",
    "        rating = row['ratings']\n",
    "        prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "        diff = prediction - rating # vTu - y\n",
    "        obj += diff*diff\n",
    "        gU.loc[user] += 2*diff*V.loc[film]\n",
    "        gV.loc[film] += 2*diff*U.loc[user]\n",
    "    return obj, gU, gV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "for i in range(iterations):\n",
    "    obj, gU, gV = objective_gradient(Y, U, V)\n",
    "    print(\"Iteration\", i, \"Objective function: \", obj)\n",
    "    U -= learn_rate*gU\n",
    "    V -= learn_rate*gV   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 Code Answer\n",
    "\n",
    "def prediction(Y,U,V):\n",
    "    pred_df = pd.DataFrame(index = Y.index, columns = ['prediction'])\n",
    "    abs_error_df = pd.DataFrame(index = Y.index, columns = ['absolute error'])\n",
    "    for i in Y.index:\n",
    "        row = Y.iloc[i]\n",
    "        user = row['users']\n",
    "        film = row['movies']\n",
    "        rating = row['ratings']\n",
    "        pred_df.loc[i] = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "        abs_error_df.loc[i] = abs(pred_df.iloc[i, 0]-rating)\n",
    "        \n",
    "    return pred_df, abs_error_df\n",
    "\n",
    "pred_df, abs_error_df = prediction(Y, U, V)\n",
    "Y['prediction'] = pred_df\n",
    "Y['absolute error'] = abs_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7 Code Answer\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def compute_obj(Y, U, V):\n",
    "    obj = 0\n",
    "    for i in Y.index:\n",
    "        row = Y.iloc[i]\n",
    "        user = row['users']\n",
    "        film = row['movies']\n",
    "        rating = row['ratings']\n",
    "        prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "        diff = prediction - rating # vTu - y\n",
    "        obj += diff*diff\n",
    "    return obj\n",
    "\n",
    "def obj_gradient(rating, u, v):\n",
    "    prediction = np.dot(u, v)\n",
    "    diff = prediction - rating\n",
    "    gU = 2* diff * v\n",
    "    gV = 2* diff * u\n",
    "\n",
    "    return gU, gV\n",
    "\n",
    "\n",
    "def SGD(Y, U, V, learn_rate = 0.01, max_iter = 100, check_obj = 1000):\n",
    "    update_counter = 0\n",
    "    obj_prev = None\n",
    "    converge = False\n",
    "    \n",
    "    num_updates = []\n",
    "    objectives = []\n",
    "    idx_list = Y.index.values\n",
    "    for iteration in range(max_iter):\n",
    "        if converge:\n",
    "            break\n",
    "        np.random.shuffle(idx_list)\n",
    "        for i in idx_list:\n",
    "            if converge:\n",
    "                break\n",
    "            row = Y.iloc[i]\n",
    "            user = row['users']\n",
    "            film = row['movies']\n",
    "            rating = row['ratings']            \n",
    "            gU, gV = obj_gradient(rating, U.loc[user], V.loc[film])\n",
    "            U.loc[user] -= learn_rate * gU\n",
    "            V.loc[film] -= learn_rate * gV \n",
    "            update_counter += 1\n",
    "            if update_counter %check_obj == 0:\n",
    "                obj = compute_obj(Y, U, V)\n",
    "                num_updates.append(update_counter)\n",
    "                objectives.append(obj)\n",
    "                print('Update %s times, objective %s'%(update_counter, obj))\n",
    "                if obj_prev == None or obj_prev > obj:\n",
    "                    obj_prev = obj\n",
    "                else:\n",
    "                    converge = True\n",
    "                    \n",
    "    plt.plot(num_updates, objectives, 'rx-')\n",
    "    plt.title('Objectives over updates')\n",
    "    plt.show()\n",
    "                    \n",
    "    return U, V                \n",
    "            \n",
    "    \n",
    "q = 2\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)\n",
    "\n",
    "U, V = SGD(Y, U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(V[0],V[1],'rx')\n",
    "plt.title('Movie map')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(U[0],U[1],'bx')\n",
    "plt.title('User map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for question 8 here.\n",
    "ratings = pd.read_csv(\"./ml-latest-small/ratings.csv\") \n",
    "Y_full = pd.DataFrame({'users': ratings['userId'], 'movies': ratings['movieId'], 'ratingsorig': ratings['rating']})\n",
    "Y_full['ratings'] = Y_full['ratingsorig'] - np.mean(Y_full['ratingsorig'])\n",
    "indexes_unique_users = ratings['userId'].unique()\n",
    "n_users = indexes_unique_users.shape[0]\n",
    "indexes_unique_movies = ratings['movieId'].unique()\n",
    "n_movies = indexes_unique_movies.shape[0]\n",
    "q = 2\n",
    "U = pd.DataFrame(np.random.normal(size=(n_users, q))*0.001, index=indexes_unique_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)\n",
    "\n",
    "# max_iter should be larger, we just put 10 here for making it faster.\n",
    "U, V = SGD(Y_full, U, V, max_iter = 10, check_obj = Y_full.shape[0]) # more iterations are needed for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(V[0],V[1],'rx')\n",
    "plt.title('Movie map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
